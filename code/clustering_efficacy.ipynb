{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f29276d-137f-410e-9141-ce29f0023425",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dcwetk.cwe_distance import *\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from frequency_grapher import *\n",
    "import glob\n",
    "from tqdm.notebook import tqdm\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from sklearn.cluster import AffinityPropagation\n",
    "from nltk.probability import FreqDist\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59513b3c-f821-4125-abd5-4c6d5f773b87",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f6b70117f4640199b90dd68d5797ea7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/112 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get words by number of part of speech\n",
    "vocab = dict()\n",
    "\n",
    "for name in tqdm(glob.glob('byp_docs_with_relational_embeddings/*.pickle')):\n",
    "    yr = int(name[-11:-7])\n",
    "    \n",
    "    if 1880 <= yr <= 1950:\n",
    "        with open(name, 'rb') as f:\n",
    "            docs = pickle.load(f)\n",
    "            f.close()\n",
    "            \n",
    "        for doc in docs:\n",
    "            for sent in doc:\n",
    "                for tok in sent:\n",
    "                    for lem in tok:\n",
    "                        if lem.lemma not in vocab.keys():\n",
    "                            vocab[lem.lemma] = set()\n",
    "                        vocab[lem.lemma].add(lem.pos_tag)\n",
    "                            \n",
    "        del docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "342a6038-dbd4-4cc4-8ac7-89ad1469ec34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to list\n",
    "vocab_posfreq = [(tok, len(pos)) for tok, pos in vocab.items() if len(pos) >= 2]\n",
    "\n",
    "# take random sample - overestimate to account for WUMs that are too small to cluster\n",
    "vocab_sample = random.sample(vocab_posfreq, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71d84dd3-e58f-4b7e-b6cc-4516bc962a86",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec3b496f06e94cb18ef410d68b25fe73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/112 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1880\n",
      "173\n",
      "\n",
      "1881\n",
      "214\n",
      "\n",
      "1882\n",
      "221\n",
      "\n",
      "1883\n",
      "249\n",
      "\n",
      "1884\n",
      "311\n",
      "\n",
      "1885\n",
      "339\n",
      "\n",
      "1886\n",
      "350\n",
      "\n",
      "1887\n",
      "377\n",
      "\n",
      "1888\n",
      "390\n",
      "\n",
      "1889\n",
      "404\n",
      "\n",
      "1890\n",
      "409\n",
      "\n",
      "1891\n",
      "447\n",
      "\n",
      "1892\n",
      "484\n",
      "\n",
      "1893\n",
      "513\n",
      "\n",
      "1894\n",
      "532\n",
      "\n",
      "1895\n",
      "542\n",
      "\n",
      "1896\n",
      "562\n",
      "\n",
      "1897\n",
      "576\n",
      "\n",
      "1898\n",
      "590\n",
      "\n",
      "1899\n",
      "627\n",
      "\n",
      "1900\n",
      "643\n",
      "\n",
      "1901\n",
      "669\n",
      "\n",
      "1902\n",
      "691\n",
      "\n",
      "1903\n",
      "714\n",
      "\n",
      "1904\n",
      "724\n",
      "\n",
      "1905\n",
      "761\n",
      "\n",
      "1906\n",
      "765\n",
      "\n",
      "1907\n",
      "776\n",
      "\n",
      "1908\n",
      "793\n",
      "\n",
      "1909\n",
      "820\n",
      "\n",
      "1910\n",
      "836\n",
      "\n",
      "1911\n",
      "848\n",
      "\n",
      "1912\n",
      "855\n",
      "\n",
      "1913\n",
      "872\n",
      "\n",
      "1914\n",
      "885\n",
      "\n",
      "1915\n",
      "887\n",
      "\n",
      "1916\n",
      "888\n",
      "\n",
      "1917\n",
      "893\n",
      "\n",
      "1918\n",
      "897\n",
      "\n",
      "1919\n",
      "910\n",
      "\n",
      "1920\n",
      "932\n",
      "\n",
      "1921\n",
      "933\n",
      "\n",
      "1922\n",
      "943\n",
      "\n",
      "1923\n",
      "952\n",
      "\n",
      "1924\n",
      "958\n",
      "\n",
      "1925\n",
      "961\n",
      "\n",
      "1926\n",
      "972\n",
      "\n",
      "1927\n",
      "973\n",
      "\n",
      "1928\n",
      "976\n",
      "\n",
      "1929\n",
      "981\n",
      "\n",
      "1930\n",
      "987\n",
      "\n",
      "1931\n",
      "989\n",
      "\n",
      "1932\n",
      "991\n",
      "\n",
      "1933\n",
      "992\n",
      "\n",
      "1934\n",
      "992\n",
      "\n",
      "1935\n",
      "996\n",
      "\n",
      "1936\n",
      "996\n",
      "\n",
      "1937\n",
      "996\n",
      "\n",
      "1938\n",
      "996\n",
      "\n",
      "1939\n",
      "996\n",
      "\n",
      "1940\n",
      "998\n",
      "\n",
      "1941\n",
      "998\n",
      "\n",
      "1944\n",
      "998\n",
      "\n",
      "1946\n",
      "999\n",
      "\n",
      "1948\n",
      "1000\n",
      "\n",
      "1949\n",
      "1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# get WUMs\n",
    "embeddings = {}\n",
    "postags = {}\n",
    "for name in tqdm(glob.glob('byp_docs_with_relational_embeddings/*.pickle')):\n",
    "    yr = int(name[-11:-7])\n",
    "    \n",
    "    if 1880 <= yr < 1950:\n",
    "        with open(name, 'rb') as f:\n",
    "            docs = pickle.load(f)\n",
    "            f.close()\n",
    "            \n",
    "        for doc in docs:\n",
    "            for sent in doc:\n",
    "                for tok in sent:\n",
    "                    for lem in tok:\n",
    "                        if lem.lemma in [i[0] for i in vocab_sample]:\n",
    "                            if lem.lemma not in embeddings.keys():\n",
    "                                embeddings[lem.lemma] = []\n",
    "                            if lem.lemma not in postags.keys():\n",
    "                                postags[lem.lemma] = []\n",
    "                                \n",
    "                            embeddings[lem.lemma].append(lem.embedding)\n",
    "                            postags[lem.lemma].append(lem.pos_tag)\n",
    "                            \n",
    "        print(yr)\n",
    "        print(len(embeddings))\n",
    "        print()\n",
    "                            \n",
    "        del docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44228ca6-16cb-457f-b0ab-69b53a559e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean and reformat data\n",
    "embeddings_list = [(tok, embed) for tok, embed in embeddings.items()]\n",
    "postags_list = [(tok, postag) for tok, postag in postags.items()]\n",
    "data = [(tok, embed, postag) for ((tok, embed), (_, postag)) in zip(embeddings_list, postags_list)]\n",
    "data_cleaned = []\n",
    "for tok, embed, postag in data:\n",
    "    if len(embed) >= 128:\n",
    "        if len(embed) > 1024:\n",
    "            data_sampled = random.sample(list(zip(embed, postag)), 1024)\n",
    "            new_embed, new_postag = zip(*data_sampled)\n",
    "            data_cleaned.append((tok, new_embed, new_postag))\n",
    "        else:\n",
    "            data_cleaned.append((tok, embed, postag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9c474716-2917-4040-a7d9-b5c7400abba4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d525183f23754b3a9fdde01938891ced",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/besalelir1/anaconda3/lib/python3.8/site-packages/sklearn/cluster/_affinity_propagation.py:246: ConvergenceWarning: Affinity propagation did not converge, this model will not have any cluster centers.\n",
      "  warnings.warn(\"Affinity propagation did not converge, this model \"\n",
      "/home/besalelir1/anaconda3/lib/python3.8/site-packages/sklearn/cluster/_affinity_propagation.py:246: ConvergenceWarning: Affinity propagation did not converge, this model will not have any cluster centers.\n",
      "  warnings.warn(\"Affinity propagation did not converge, this model \"\n",
      "/home/besalelir1/anaconda3/lib/python3.8/site-packages/sklearn/cluster/_affinity_propagation.py:246: ConvergenceWarning: Affinity propagation did not converge, this model will not have any cluster centers.\n",
      "  warnings.warn(\"Affinity propagation did not converge, this model \"\n",
      "/home/besalelir1/anaconda3/lib/python3.8/site-packages/sklearn/cluster/_affinity_propagation.py:246: ConvergenceWarning: Affinity propagation did not converge, this model will not have any cluster centers.\n",
      "  warnings.warn(\"Affinity propagation did not converge, this model \"\n",
      "/home/besalelir1/anaconda3/lib/python3.8/site-packages/sklearn/cluster/_affinity_propagation.py:246: ConvergenceWarning: Affinity propagation did not converge, this model will not have any cluster centers.\n",
      "  warnings.warn(\"Affinity propagation did not converge, this model \"\n",
      "/home/besalelir1/anaconda3/lib/python3.8/site-packages/sklearn/cluster/_affinity_propagation.py:246: ConvergenceWarning: Affinity propagation did not converge, this model will not have any cluster centers.\n",
      "  warnings.warn(\"Affinity propagation did not converge, this model \"\n",
      "/home/besalelir1/anaconda3/lib/python3.8/site-packages/sklearn/cluster/_affinity_propagation.py:246: ConvergenceWarning: Affinity propagation did not converge, this model will not have any cluster centers.\n",
      "  warnings.warn(\"Affinity propagation did not converge, this model \"\n"
     ]
    }
   ],
   "source": [
    "# make clusters\n",
    "AP = AffinityPropagation(max_iter=250, random_state=10)\n",
    "ap = lambda i: AP.fit_predict(i)\n",
    "clustered_data = [(tok, embed, postag, ap(embed)) for tok, embed, postag in tqdm(data_cleaned)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5695fd8d-2c15-4e4f-b094-2ff8d7997b1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118\n"
     ]
    }
   ],
   "source": [
    "# filter out clusters that failed to converge\n",
    "cdata_cleaned = [i for i in clustered_data if len(set(i[3])) > 1]\n",
    "print(len(cdata_cleaned))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e0f68b28-63d0-4ed2-afe6-993264510afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load into dfs\n",
    "dfs = {}\n",
    "for tok, embed, postag, cluster in cdata_cleaned:\n",
    "    x, y = zip(*PCA(n_components=2).fit_transform(embed))\n",
    "    dfs[tok] = pd.DataFrame({'x': x, 'y': y, 'pos': postag, 'cluster': cluster})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "4715946b-0345-49e1-b5d3-02d039646099",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0387c07e469345d6bd7771f32652f080",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/118 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# make master df with info\n",
    "meta_df = {'tok': [], 'n_clusters': [], 'n_pos': [], 'pos_list': [], 'n_homogeneous_clusters': []}\n",
    "for tok, df in tqdm(dfs.items()):\n",
    "    meta_df['tok'].append(tok)\n",
    "    meta_df['n_clusters'].append(len(df['cluster'].unique()))\n",
    "    meta_df['n_pos'].append(len(df['pos'].unique()))\n",
    "    # calculate n of homogenous clusters\n",
    "    count = 0\n",
    "    for cl in df['cluster'].unique():\n",
    "        # filter by cluster\n",
    "        dff = df[df['cluster'] == cl]\n",
    "        # if length of dff['pos'] == 1:\n",
    "        if len(dff['pos']) == 1:\n",
    "            count += 1\n",
    "            \n",
    "    meta_df['n_homogeneous_clusters'].append(count)\n",
    "    meta_df['pos_list'].append('|'.join(list(df['pos'].unique())))\n",
    "    \n",
    "mdf = pd.DataFrame(meta_df)\n",
    "mdf['accuracy'] = mdf.apply(lambda i: i['n_homogeneous_clusters'] / i['n_clusters'], axis=1)\n",
    "mdf.sort_values(by='n_pos', inplace=True, axis=0, ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "96f27af1-6466-4ba5-baad-915c2396c5ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPEARMAN\n",
      "Correlation coefficient: 0.17\n",
      "PVal: 0.07\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import spearmanr, pearsonr\n",
    "\n",
    "print('SPEARMAN')\n",
    "corr, p = spearmanr(mdf['n_pos'], mdf['accuracy'])\n",
    "print('Correlation coefficient: ' + str(np.round(corr, 2)))\n",
    "print('PVal: ' + str(np.round(p, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "267ec00b-3cc2-45ab-b24c-838c3d66d6d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09\n"
     ]
    }
   ],
   "source": [
    "print(np.round(sum(mdf['n_homogeneous_clusters']) / sum(mdf['n_clusters']), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6a950d-b9b0-4e49-b43b-3ddb2b1d62af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
